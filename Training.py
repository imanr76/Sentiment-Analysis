import torchfrom torch import nnfrom torch.utils.data import DataLoader, Datasetimport matplotlib.pyplot as pltfrom sklearn.metrics import classification_reportimport nltkfrom nltk.tokenize import word_tokenizeimport refrom nltk.stem import WordNetLemmatizer# nltk.download("punkt")# nltk.download('wordnet')import data_preparationfrom data_preparation import datasetdata_preparation.max_lenif torch.cuda.is_available():   device = torch.device("cuda")if torch.backends.mps.is_available():    device = torch.device("mps")    vocabulary = torch.load("./models/vocabulary.pth")training_dataset = torch.load("./data/training/training_dataset.pth")validation_dataset = torch.load("./data/validation/validation_dataset.pth")test_dataset = torch.load("./data/test/test_dataset.pth")train_loader = DataLoader(training_dataset, batch_size = 64, shuffle = True)def cleanup_text(text):    text = text.lower()    text = re.sub(r"[^a-z.?!:)( \n]+", "", text)    text = re.sub(r"\.{2,}", ".", text)    text = re.sub(r"\.{2,}", "!", text)    text = re.sub(r"\.{2,}", "?", text)    text = re.sub(r"\.{2,}", ")", text)    text = re.sub(r"\.{2,}", "(", text)    text = re.sub(r"\.{2,}", ":", text)    return textdef process_reviews(review, tokenizer, lemmatizer, vocabulary):    review_cleaned = cleanup_text(review)    review_tokenized = tokenizer(review_cleaned)    lemmatized_text = [lemmatizer.lemmatize(word) for word in review_tokenized]    review_processed = vocabulary(lemmatized_text)    return review_processeddef predict(model, tokenizer, vocabulary, lemmatizer, reviews):    predictions = []    for review in reviews:        review = process_reviews(review, tokenizer, lemmatizer, vocabulary)        prediction = torch.argmax(model(torch.tensor(review).reshape(1, -1)), dim = 1)        if prediction == 1:            predictions.append("Positive")        if prediction == 1:            predictions.append("Negative")    return predictions#%%class sentiment(nn.Module):        def __init__(self, vocab_len, embed_dim = 20, lstm_size = 20, bidirectional = True, num_layers = 1):        super().__init__()        self.num_layers = num_layers        self.bidirectional = bidirectional                self.embeddings = nn.Embedding(vocab_len, embed_dim)        self.lstm = nn.LSTM(embed_dim, hidden_size = lstm_size, batch_first = True, bidirectional = bidirectional, dropout = 0.0)                if self.bidirectional:            self.linear_size = lstm_size * 2        else:            self.linear_size = lstm_size                    self.linear = nn.Linear(self.linear_size, 2)        self.softmax = nn.Softmax(dim = 1)        def forward(self, inputs):        x = self.embeddings(inputs)        x = self.lstm(x)[1][0]        if self.bidirectional:            x = x[-2 :, :, :]            x = x.permute(1,0,2).reshape(x.size(1),-1)        else:            x = x[-1, :, :]            x = x.reshape(x.size(0),-1)        x = self.linear(x)        x = self.softmax(x)        return x        def train(self, train_dataloader, validation_dataset, epochs, loss_func, optimizer):        self.loss_func = loss_func        num_samples = len(train_loader.dataset)        loss_train_list = []        accuracy_train_list = []        loss_validation_list = []        accuracy_validation_list = []        validation_dataset = validation_dataset[:, :].to(device)                for epoch in range(epochs):                correct_sentiments = 0            epoch_loss = 0                        for data in train_dataloader:                data = data.to(device)                review = data[:, :-1]                sentiment_real = data[:, -1]                                sentiment_pred = self.forward(review)                sentiment_pred_args = torch.argmax(sentiment_pred, dim = 1)                correct_sentiments += torch.sum(sentiment_pred_args == sentiment_real).item()                                optimizer.zero_grad()                loss_train = self.loss_func(sentiment_pred, sentiment_real)                loss_train.backward()                epoch_loss += loss_train.item()                optimizer.step()                        validation_preds = self.forward(validation_dataset[:, :-1])            loss_validatoion = self.loss_func(validation_preds, validation_dataset[:, -1]).item()            accuracy_validation = (torch.sum(torch.argmax(validation_preds, dim = 1) == validation_dataset[:, -1]).item() / len(validation_dataset))                        loss_train_list.append(epoch_loss/len(train_loader))            accuracy_train_list.append(correct_sentiments/num_samples * 100)            loss_validation_list.append(loss_validatoion)            accuracy_validation_list.append(accuracy_validation * 100)                                    print(f"epoch : {epoch + 1}, training loss : {epoch_loss/len(train_loader):.4f}, training accuracy : {correct_sentiments/num_samples * 100:.1f}")            print(f"epoch : {epoch + 1}, validation loss : {loss_validatoion:.4f}, validation accuracy : {accuracy_validation * 100:.1f}")            print()                    plt.figure()        plt.plot(range(1, epochs + 1), loss_train_list, label = "training loss")        plt.plot(range(1, epochs + 1), loss_validation_list, label = "validation loss")        plt.legend()        plt.xlabel("epochs")        plt.ylabel("loss")                plt.figure()        plt.plot(range(1, epochs + 1), accuracy_train_list, label = "training accuracy")        plt.plot(range(1, epochs + 1), accuracy_validation_list, label = "validatoin accuracy")        plt.legend()        plt.xlabel("epochs")        plt.ylabel("accuracy")            def evaluate(self, test_dataset):        predictions = model.forward(test_dataset[:, :-1])        predictions_arg = torch.argmax(predictions, dim = 1)        accuracy = torch.sum(predictions_arg == test_dataset[:, -1]).item() / len(test_dataset) * 100        loss = self.loss_func(predictions, test_dataset[:, -1]).item()                report = classification_report(test_dataset[:, -1], predictions_arg, output_dict=True, zero_division=0)                print(f"test set loss : {loss:.4}, test set accuracy : {accuracy:.1f}")                return report                     import timeseed = 10start_time = time.time()torch.manual_seed(seed)torch.cuda.manual_seed_all(seed)torch.backends.cudnn.deterministic = Truetorch.backends.cudnn.benchmark = Falsetorch.cuda.empty_cache()torch.use_deterministic_algorithms(True)torch.mps.manual_seed(seed)torch.mps.empty_cache()model = sentiment(len(vocabulary)).to(device)loss_func = nn.CrossEntropyLoss()loss_funt = nn.BCELoss()optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)model.train(train_loader, validation_dataset, 100, loss_func, optimizer)model.to("cpu")report = model.evaluate(test_dataset)elapsed_time = time.time() - start_timeprint( "Time: ", elapsed_time)reviews =  ["love it", "it was too loose" ,"This is a nice computer, I love using it and i will recommend you to buy it as soon as possible"]predictions = predict(model, word_tokenize, WordNetLemmatizer(), vocabulary, reviews)for review, prediction in zip(reviews, predictions):    print(f"Review : '{review}'\nPredicted Sentiment : {prediction}\n")